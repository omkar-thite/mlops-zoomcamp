- Add hyper parameter tuning into noteobok.  
- Explore results and select best model base on results.


- Train model using xgboost.
- Tune with hyperopt
- Log all information into mlflow

hyperopt : Bayesian hyperparameter searchin g library
- Your model is function that takes parameters and outputs some value as output.
- fmin: used to minimize output of model function.
- tpe: algorithm that controls the logic
- hp : module contains methods that defines search space (range for each hyperp)
- STATUS_OK: signal that we will send at end of each run to tell hyperopt that objectve funciton has run successfully.
- Trials: object that keeps track of information from each run.

